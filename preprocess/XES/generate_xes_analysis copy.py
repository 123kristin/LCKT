import os
import json
from tqdm import tqdm
from openai import OpenAI
import re

# ========== é…ç½® OpenAI ========== #
client = OpenAI(
    api_key="YOUR API KEY",
    base_url="xxx"
)

# ========== é…ç½®è·¯å¾„ ========== #
data_dir = "../data/XES3G5M/metadata"
save_path = "../data/XES3G5M"
image_dir = os.path.join(data_dir, "images")
save_dir = os.path.join(save_path, "generate_analysis")
os.makedirs(save_dir, exist_ok=True)

questions_file = os.path.join(data_dir, "questions.json")
temp_file = os.path.join(save_dir, "Generated_XES_Analysis_temp.json")
final_file = os.path.join(save_dir, "Generated_XES_Analysis.json")

# ========== å·¥å…·å‡½æ•° ========== #
def get_image_paths(question_id):
    prefix = f"question_{question_id}-image_"
    return sorted([fname for fname in os.listdir(image_dir) if fname.startswith(prefix)])


def build_prompt(question_id, item):
    content = item["content"]
    answer = item.get("answer", [""])[0]
    qtype = item.get("type", "æœªçŸ¥")
    kc = item.get("kc_routes", [])
    options = item.get("options", {})
    images = get_image_paths(question_id)

    prompt = f"""ä½ æ˜¯ä¸€ä½æ“…é•¿å°å­¦æ•°å­¦è®²è§£çš„æ•™å­¦åŠ©æ‰‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä¸ºä»¥ä¸‹æ•°å­¦é¢˜ç›®ç”Ÿæˆä¸€ä»½å®Œæ•´ä¸”æ¸…æ™°çš„è§£æè¿‡ç¨‹ã€‚è¯·æ ¹æ®é¢˜ç›®çš„å†…å®¹å’Œå¯¹åº”çš„çŸ¥è¯†ç‚¹ï¼Œå¼•å¯¼å­¦ç”Ÿä¸€æ­¥æ­¥å¾—å‡ºæ­£ç¡®ç­”æ¡ˆã€‚

è¦æ±‚ï¼š
- è¯´æ˜è§£é¢˜æ‰€ä½¿ç”¨çš„çŸ¥è¯†ç‚¹ã€‚
- åˆ†æ­¥éª¤è¿›è¡Œè®²è§£ï¼Œé€»è¾‘æ¸…æ™°ã€‚
- å¦‚æœæœ‰é€‰é¡¹ï¼Œè¯·æŒ‡å‡ºæ­£ç¡®ç­”æ¡ˆå¹¶è§£é‡Šé”™è¯¯é€‰é¡¹ã€‚
- å¦‚æœé¢˜ç›®æœ‰é…å›¾ï¼Œè¯·åœ¨è§£æä¸­é€‚å½“æç¤ºå›¾åƒçš„ä½¿ç”¨ã€‚
- ä½¿ç”¨ç®€æ´ã€æ˜“æ‡‚çš„ä¸­æ–‡è¯­è¨€é£æ ¼ã€‚

é¢˜ç›®ç±»å‹ï¼š{qtype}

é¢˜ç›®ï¼š
{content}

å‚è€ƒçŸ¥è¯†ç‚¹ï¼š
{'; '.join(kc)}

ç­”æ¡ˆï¼š
{answer}
"""

    if images:
        prompt += f"\n\næç¤ºï¼šæ­¤é¢˜åŒ…å« {len(images)} å¼ å›¾åƒï¼Œä¾‹å¦‚ {images[0]}"

    if options:
        prompt += "\n\né€‰é¡¹ï¼š\n" + "\n".join([f"- {key}: {value}" for key, value in options.items()])

    return prompt


def call_gpt(prompt, model="gpt-4o"):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful and knowledgeable educational assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"[GPT Error] {e}")
        return None

def load_from_json(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_to_json(data, file_path):
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ========== ä¸»å¤„ç†é€»è¾‘ ========== #
if __name__ == "__main__":
    print("ğŸ” Loading question data...")
    with open(questions_file, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    if isinstance(raw_data, dict):
        questions = list(raw_data.items())  # list of (qid, dict)
    elif isinstance(raw_data, list):
        questions = list(enumerate(raw_data))
    else:
        raise ValueError("âŒ Invalid questions.json format.")

    # å·²å®Œæˆç¼“å­˜
    existing_results = load_from_json(temp_file)
    done_ids = set([item["questions"] for item in existing_results])
    remaining = [(qid, item) for qid, item in questions if int(qid) not in done_ids]

    print(f"âœ… å·²å®Œæˆ {len(done_ids)}ï¼Œå¾…ç”Ÿæˆ {len(remaining)}")

    all_results = existing_results.copy()

    for qid, item in tqdm(remaining, total=len(remaining), desc="Generating Explanations"):
        prompt = build_prompt(qid, item)
        explanation = call_gpt(prompt)

        if explanation is None:
            continue

        result = {
            "questions": int(qid),
            "content": item["content"],
            "answer": item.get("answer", [""])[0],
            "type": item.get("type", "æœªçŸ¥"),
            "kc_routes": item.get("kc_routes", []),
            "options": item.get("options", {}),
            "original_analysis": item.get("analysis", ""),
            "generated_explanation": explanation
        }

        all_results.append(result)
        save_to_json(all_results, temp_file)

    save_to_json(all_results, final_file)
    print(f"\nâœ… ç”Ÿæˆå®Œæ¯•ï¼å…±ç”Ÿæˆ {len(all_results)} æ¡è§£æã€‚")
    print(f"ğŸ“„ ç»“æœä¿å­˜åœ¨ï¼š{final_file}")